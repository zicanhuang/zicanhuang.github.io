---
layout: post
title: 公平调度
date: 2018-11-30
categories: storage
tags: Markdown
---

# 一、linux中公平调度机制(CFQ)
首先这个公平指的是对进程的公平，即操作系统在多个进程竞争IO资源时试图让进程可以公平地使用IO资源。

IO资源往往有两种衡量方式，带宽和IOPS，当请求大小很大时或请求地址比较连续时，带宽容易成为瓶颈；而当请求大小比较小、并且多是随机请求（难以合并）时，IOPS容易成为瓶颈。因为操作系统并不知道进程倾向于以哪种方式利用IO资源，因此操作系统采用对IO设备的占用时间来进行调度，即尽可能地让各个进程公平地占用IO设备的时间。

linux默认采用CFQ(Completely Fair Queueing)来保证进程间公平地使用IO资源。

新版的CFQ支持cgroup(control group)，全部进程被分成了若干个cgroup进行管理。cgroup有policy，policy限定cgroup对IO资源的访问上限。CFQ记录每个cgroup占用的IO时间(vdisktime)，这个时间是虚拟时间，即实际占用IO时间/cgroup的权值，这个权值是根据cgroup的policy定的。所以CFQ对于cgroup之间的管理策略是：
每次分配一个时间片，这个时间片分配给vdisktime最小的cgroup。分配比例大的cgroup虚拟IO时间增长地慢，分配比例小的cgroup虚拟IO时间增长的快，以此来保证各个cgroup之间成比例地占用IO资源。从实现上，所有的cgroup被放在一棵红黑树里，以vdisktime为key进行排序，每次从红黑树中选出vdisktime最小的cgroup进行处理。

在同一个cgroup里面，CFQ保证进程间的IO资源分配公平。

进程是有优先级的，可以通过nice命令设置进程的优先级。所以CFQ其实是保证了同一个cgroup中同一个优先级内的进程在IO访问时间上是公平的，不同优先级之间优先级高的先访问，分成三种优先级RT(RealTime)，BE(BestEffort)和IDLE，RT优先级最高，只有当没有RT进程访问IO资源时，BE进程才能访问IO资源。

在同一个优先级中，每个进程有一个服务队列cfq_queue，CFQ每次把时间片分配给IO服务时间(service_time)最小的cfq_queue，所以这里又用一棵红黑树维护了各个进程的服务队列，以service_time为key。

当选择好了cfq_queue后，就要从队列中选择一个请求进行派发。对每个进入cfq_queue的请求会放入两个数据结构中：一个是FIFO的队列，用来避免请求超时，一个是以访问扇区为key的红黑树。默认从红黑树中取请求进行处理，当FIFO队头的请求达到deadline时处理该请求，防止请求饿死。

另外提一句：linux中同步请求和异步请求是分开处理的，因为只有当请求是同步的时候CFQ才能区分IO请求来自哪个进程，这里说的异步指的是进程把数据先写到buffer/cache，后台再从内存的buffer/cache中把数据同步到硬盘的IO请求。(而非aio或libaio机制，这些上层的异步机制，在内核中都是同步实现的)。

# 二、WFQ(Weighted Fair Queueing)
这篇论文(Analysis and simulation of a fair queueing algorithm)引用量接近3000，可谓是公平调度中的鼻祖。

WFQ主要关注的其实是网络包(packet)的拥塞控制，初衷是为了 通过排队算法提供一种保护机制，使得每个包来源只能对其他包来源造成有限的影响。
场景是有多个源(source)同时把包发送给同一个交换机，来自同一个源的包组成flow，然后交换机暂存和把这些包转发出去，交换机只有一个出口，出口有固定带宽C，最终要达到的效果是，在任意某个时间段内当有多个flow同时竞争这个出口带宽时，每个flow分到的带宽是相同的（在带权值(weight)的场景下，每个flow分到的带宽跟其weight是成比例的）。
这个出口其实是串行的，即每次都是1bit 1bit的传。

假设一种理想的情况，即所有的包都是1bit大小，然后交换机采用bit-by-bit round-robin的方式处理包，即比如有两个flow A和B, A发1bit，B发1bit，然后 A发1bit，B发1bit，如此往复。那么这时候，带宽分配就是完全公平。

但是实际中包的大小的并不是固定的，也不可能把包切成1bit大小的分片按bit-by-bit round-robin方式发送，但是想取得类似的效果，所以WFQ采用模拟bit-by-bit round-robin的方式来调度包的发送。

WFQ给每个包打上两个tag，一个开始tag，一个结束tag，这两个tag的计算方式为：

$$
S(p_{f}^{j})=max\left \{  v(A(p_{f}^{j})),F(p_{f}^{j-1})\right \},j\geqslant 1 \\
F(p_{f}^{j})=S(p_{f}^{j})+\frac{l_{f}^{j}}{r_{f}},j\geqslant 1 
$$

其中，$p_{f}^{j}$表示flow f中的第j个包，$A\left ( p_{f}^{j}\right )$表示包$p_{f}^{j}$的实际到来时间，$l_{f}^{j}$表示包$p_{f}^{j}$的长度，$r_{f}$表示flow f的权值。$S(p_{f}^{j})$表示$p_{f}^{j}$的开始tag，$F(p_{f}^{j})$表示$p_{f}^{j}$的结束tag, $F(p_{f}^{0})=0$。$v\left ( t\right )$是里面最难理解的。$v\left ( t\right )$指的是t时刻如果按照bit-by-bit round-robin方式现在到达的轮数。更形式化点的定义是

$$
\frac{dv\left ( t\right )}{dt}=\frac{C}{\sum_{j\in B\left (t \right )}r_j}
$$

所以WFQ怎么工作呢，WFQ会在每个包到来的时候根据上面公式计算两个tag，当有多个flow竞争时，选择结束tag更小的包进行服务。

举个例子，如图1所示，假设有两个flow A和B，flow A每个包长度都是3 bit，flow B每个包都是2 bit，服务器的带宽为1 bit/s。
当flow B第一个包到来的时候S=max{v(1),0}=1，F=S+2/0.5=5。当A第一个包完成时只有flow B有包，则发B第一个包。当flow B第二个包到来时，进入round2，S=max{2,5}=5，F=S+4=9。当flow A第二个包到来时，S=max{2,3}=3，F=S+6=9。所以当flow B第二个包服务完成时，flow A和flow B第一个未服务的包的结束tag都是9，则按先来的B第二个包先服务。flow B的第三个包到来时，S=max{3,9}=9，F=S+4=13，则当B第二个包完成时，flow A和flow B的第一个未服务的包的结束tag分别是9和13，则先服务flow A的第2个包。

总的来说就大概这么个流程，当然这个例子里，因为总的处理能力太小，一秒只能完成1bit，包又来的相对快，导致这个开始tag的计算基本上都是基于同一个flow中上一个包的结束tag来计算的。当总的处理带宽变得比较大时，开始tag的计算就会比较大的依赖于bit-by-bit RR在包到来时间点所进行的轮数。

WFQ的实现比较依赖于$v\left (t \right )$的计算，需要去模拟一个bit-by-bit round robin服务器的处理流程，所以计算复杂度比较高，效率比较低。此外，WFQ还有个缺点就是他基于的假设是服务器的处理能力$C$是恒定的，当服务器的处理能力随时间变化时，WFQ很难保证公平。



# 三、SFQ(Start-time Fair Queueing)
SFQ是在WFQ的基础上进行改进而来，先直接给出整个算法：

在SFQ中，与WFQ相同，每个到来的包都会计算出两个tag，一个开始tag和一个结束tag，这两个tag的公式也和WFQ中完全相同：

$$
S(p_{f}^{j})=max\left \{  v(A(p_{f}^{j})),F(p_{f}^{j-1})\right \},j\geqslant 1 \\
F(p_{f}^{j})=S(p_{f}^{j})+\frac{l_{f}^{j}}{r_{f}},j\geqslant 1 
$$

区别在于两点：
- 一是SFQ中$v\left ( t\right )$的计算方式不同，当服务器繁忙时(当前有包正在被服务)，则在真实时间为t时刻的虚拟时间$v\left ( t\right )$与当前正在被服务的包的开始tag相同。当每个繁忙时期结束时，$v\left ( t\right )$被设置成已完成的包中最大的结束tag。 
- 二是当有多个flow竞争时，选择开始tag最小的包进行服务，而不是WFQ中选择结束tag更小的包进行服务。

传统的virtual clock based(如CFQ)方法中每个flow的virtual clock累加了其自身所消耗的系统资源(归一化后的)，所以当系统中只有一个flow在跑的时候它的virtual clock会增加不少导致当后面来了多个flow时竞争资源时被unfairly惩罚了。这其实是不合理的，多个flow之间的公平应该是work-conserving的，这种公平性应该是指示了当这些活跃的flow一起竞争时应该怎样进行系统资源的划分，应该是一种无状态的策略，而不应该是定义为从整个使用资源的历史来看最终总体上各个flow的使用份额跟其权值成比例。

SFQ解决这个问题的方法是：让所有新来的活跃的flow的虚拟时钟都尽量调到当前系统的虚拟时钟，这就使得新来的flow不会因为虚拟时钟太慢而为它分配大量的带宽而造成对其他flow的不公平。

所以SFQ的解决了WFQ的两个问题，$v\left (t \right )$的计算复杂度降低了，只需要看当前正在服务的包的开始tag，并且不需要依赖于服务器带宽的恒定。

但SFQ也有一些问题，比如他没有考虑到服务器能够同时处理多个请求的情况。

# 四、SFQ(D)
当服务器能够同时处理多个包时，当一个新的包到来时，系统中可能有不止一个包正在被服务，这时候$v\left (t \right )$应该选择哪个正在被服务的包的开始tag进行计算呢。

如果$v\left (t \right )$增加的太快，可能会把那些落后的flow手动提前使得这些flow还没使用的资源被废弃掉造成对这些落后的flow的不公平。如果$v\left (t \right )$增加的太慢，落后的flow可能会突然消耗系统大量的资源使得其他flow的响应时间受影响。

这篇文章一共提出三种策略：
- Min-SFQ(D):当一个包到来时，$v\left (t \right )$采用的是当前正在被服务的包的开始tag中最小的那个。这种方式虚拟时间增加的较慢，当一个虚拟时间落后的flow突然发了很多包，这些包都会被优先处理，可能会造成后来的flow响应时间增加。
- Max-SFQ(D)：当一个包到来时，$v\left (t \right )$采用的是当前正在被服务的包的开始tag中最大的那个。这种方式虚拟时间增加的较快，当一个虚拟时间落后的flow的虚拟时间可能会不恰当的提前使得其每利用到其应有的带宽。
- 4-tag SFQ(D):前两者的折中，为每个到来的包维护两对开始/结束tag。


# 五、FIOS: 一种公平有效的闪存IO调度器(FAST'12)
作者认为把传统的为磁盘设计的公平调度算法应用在基于闪存的SSD上存在一些问题：
- **SSD读写不对称**。作者在测试时把SSD内部的写缓存给关掉了，所以测出来会有4KB的写和读在性能上差异比较大的情况，读比如平均是100us，而写基本要几毫秒，这就造成了如果把读写在调度时不加以区分，当读写负载混合时，读负载会有显著的性能下降。
- **没有考虑I/O anticipation**。I/O anticipation在磁盘的时代提出来以减少寻道提高性能，通过使得在请求结束时先暂缓后续请求的处理而期望后面一小段时间会有相邻的请求到来。在SSD时代，由于没有寻道的概念，顺序请求跟随机请求在性能上是一样的，所以I/O anticipation引入的overhead反而会降低性能。所以linux的CFQ当用在SSD上时会关掉I/O anticipation，公平调度算法如SFQ等并没有考虑I/O anticipation。但是I/O anticipation在某些时候是有必要的。比如在quanta-based的调度算法中(比如CFQ)，如果没有I/O anticipation，可能在一个flow的定额还没用完的时候就转向另一个flow。作者举了一个例子，有一个读者和一个写者同时在跑，在一个读请求服务完成后，队列中只有一个写请求，这时候调度器会直接把写请求下发，而其实一小段时间后读请求就来了，这时候这些读请求都被写请求给阻塞掉了。另一种做法是每个flow都强制占用其定额的资源，这又会浪费资源(可能一个时间片内该flow只有稀疏的请求)以及影响其他flow请求响应时间。
- **没有考虑平行性**。SSD内部往往有多个可以独立服务请求的通道(或是其他并行单元)。

# 六、FlashFQ:一种针对SSD的IO公平排队调度器(ATC’13)
FlashFQ是在SFQ(D)的基础上进行改进的。


