---
layout: post
title: 公平调度
date: 2018-11-30
categories: storage
tags: Markdown
---

# 一、linux中公平调度机制(CFQ)
首先这个公平指的是对进程的公平，即操作系统在多个进程竞争IO资源时试图让进程可以公平地使用IO资源。

IO资源往往有两种衡量方式，带宽和IOPS，当请求大小很大时或请求地址比较连续时，带宽容易成为瓶颈；而当请求大小比较小、并且多是随机请求（难以合并）时，IOPS容易成为瓶颈。因为操作系统并不知道进程倾向于以哪种方式利用IO资源，因此操作系统采用对IO设备的占用时间来进行调度，即尽可能地让各个进程公平地占用IO设备的时间。

linux默认采用CFQ(Completely Fair Queueing)来保证进程间公平地使用IO资源。

新版的CFQ支持cgroup，全部进程被分成了若干个cgroup进行管理。cgroup有policy，policy限定cgroup对IO资源的访问上限。CFQ记录每个cgroup占用的IO时间(vdisktime)，这个时间是虚拟时间，即实际占用IO时间/cgroup的权值，这个权值是根据cgroup的policy定的。所以CFQ对于cgroup之间的管理策略是：
每次分配一个时间片，这个时间片分配给vdisktime最小的cgroup。分配比例大的cgroup虚拟IO时间增长地慢，分配比例小的cgroup虚拟IO时间增长的快，以此来保证各个cgroup之间成比例地占用IO资源。从实现上，所有的cgroup被放在一棵红黑树里，以vdisktime为key进行排序，每次从红黑树中选出vdisktime最小的cgroup进行处理。

在同一个cgroup里面，CFQ保证进程间的IO资源分配公平。

进程是有优先级的，可以通过nice命令设置进程的优先级。所以CFQ其实是保证了同一个cgroup中同一个优先级内的进程在IO访问时间上是公平的，不同优先级之间优先级高的先访问，分成三种优先级RT(RealTime)，BE(BestEffort)和IDLE，RT优先级最高，只有当没有RT进程访问IO资源时，BE进程才能访问IO资源。

在同一个优先级中，每个进程有一个服务队列cfq_queue，CFQ每次把时间片分配给IO服务时间(service_time)最小的cfq_queue，所以这里又用一棵红黑树维护了各个进程的服务队列，以service_time为key。

当选择好了cfq_queue后，就要从队列中选择一个请求进行派发。对每个进入cfq_queue的请求会放入两个数据结构中：一个是FIFO的队列，用来避免请求超时，一个是以访问扇区为key的红黑树。默认从红黑树中取请求进行处理，当FIFO队头的请求达到deadline时处理该请求，防止请求饿死。

另外提一句：linux中同步请求和异步请求是分开处理的，因为只有当请求是同步的时候CFQ才能区分IO请求来自哪个进程，这里说的异步指的是进程把数据先写到buffer/cache，后台再从内存的buffer/cache中把数据同步到硬盘的IO请求。(而非aio或libaio机制，这些上层的异步机制，在内核中都是同步实现的)。

# 二、WFQ(Weighted Fair Queueing)
这篇论文(Analysis and simulation of a fair queueing algorithm)引用量接近3000，可谓是公平调度中的鼻祖。

WFQ主要关注的其实是网络包(packet)的拥塞控制，初衷是为了 通过排队算法提供一种保护机制，使得每个包来源只能对其他包来源造成有限的影响。
场景是有多个源(source)同时把包发送给同一个交换机，来自同一个源的包组成flow，然后交换机暂存和把这些包转发出去，交换机只有一个出口，出口有固定带宽C，最终要达到的效果是，在任意某个时间段内当有多个flow同时竞争这个出口带宽时，每个flow分到的带宽是相同的（在带权值(weight)的场景下，每个flow分到的带宽跟其weight是成比例的）。
这个出口其实是串行的，即每次都是1bit 1bit的传。

假设一种理想的情况，即所有的包都是1bit大小，然后交换机采用bit-by-bit round-robin的方式处理包，即比如有两个flow A和B, A发1bit，B发1bit，然后 A发1bit，B发1bit，如此往复。那么这时候，带宽分配就是完全公平。

但是实际中包的大小的并不是固定的，也不可能把包切成1bit大小的分片按bit-by-bit round-robin方式发送，但是想取得类似的效果，所以WFQ采用模拟bit-by-bit round-robin的方式来调度包的发送。

WFQ给每个包打上两个tag，一个开始tag，一个结束tag，这两个tag的计算方式为：

$$
S(p_{f}^{j})=max\left \{  v(A(p_{f}^{j})),F(p_{f}^{j-1})\right \},j\geqslant 1 \\
F(p_{f}^{j})=S(p_{f}^{j})+\frac{l_{f}^{j}}{r_{f}},j\geqslant 1 
$$

其中，$p_{f}^{j}$表示flow f中的第j个包，$A\left ( p_{f}^{j}\right )$表示包$p_{f}^{j}$的实际到来时间，$l_{f}^{j}$表示包$p_{f}^{j}$的长度，$r_{f}$表示flow f的权值。$S(p_{f}^{j})$表示$p_{f}^{j}$的开始tag，$F(p_{f}^{j})$表示$p_{f}^{j}$的结束tag, $F(p_{f}^{0})=0$。$v\left ( t\right )$是里面最难理解的。$v\left ( t\right )$指的是t时刻如果按照bit-by-bit round-robin方式现在到达的轮数。更形式化点的定义是

$$
\frac{dv\left ( t\right )}{dt}=\frac{C}{\sum_{j\in B\left (t \right )}r_j}
$$

所以WFQ怎么工作呢，WFQ会在每个包到来的时候根据上面公式计算两个tag，当有多个flow竞争时，选择结束tag更小的包进行服务。

举个例子，如图1所示，假设有两个flow A和B，flow A每个包长度都是3 bit，flow B每个包都是2 bit，服务器的带宽为1 bit/s。
当flow B第一个包到来的时候S=max{v(1),0}=1，F=S+2/0.5=5。当A第一个包完成时只有flow B有包，则发B第一个包。当flow B第二个包到来时，进入round2，S=max{2,5}=5，F=S+4=9。当flow A第二个包到来时，S=max{2,3}=3，F=S+6=9。所以当flow B第二个包服务完成时，flow A和flow B第一个未服务的包的结束tag都是9，则按先来的B第二个包先服务。flow B的第三个包到来时，S=max{3,9}=9，F=S+4=13，则当B第二个包完成时，flow A和flow B的第一个未服务的包的结束tag分别是9和13，则先服务flow A的第2个包。

总的来说就大概这么个流程，当然这个例子里，因为总的处理能力太小，一秒只能完成1bit，包又来的相对快，导致这个开始tag的计算基本上都是基于同一个flow中上一个包的结束tag来计算的。当总的处理带宽变得比较大时，开始tag的计算就会比较大的依赖于bit-by-bit RR在包到来时间点所进行的轮数。

WFQ的实现比较依赖于$v\left (t \right )$的计算，需要去模拟一个bit-by-bit round robin服务器的处理流程，所以计算复杂度比较高，效率比较低。此外，WFQ还有个缺点就是他基于的假设是服务器的处理能力$C$是恒定的，当服务器的处理能力随时间变化时，WFQ很难保证公平。



# 三、SFQ(Start-time Fair Queueing)
SFQ是在WFQ的基础上进行改进而来，先直接给出整个算法：

在SFQ中，与WFQ相同，每个到来的包都会计算出两个tag，一个开始tag和一个结束tag，这两个tag的公式也和WFQ中完全相同：

$$
S(p_{f}^{j})=max\left \{  v(A(p_{f}^{j})),F(p_{f}^{j-1})\right \},j\geqslant 1 \\
F(p_{f}^{j})=S(p_{f}^{j})+\frac{l_{f}^{j}}{r_{f}},j\geqslant 1 
$$

区别在于两点：一是SFQ中$v\left ( t\right )$的计算方式不同，当服务器繁忙时(当前有包正在被服务)，则在真实时间为t时刻的虚拟时间$v\left ( t\right )$与当前正在被服务的包的开始tag相同。当每个繁忙时期结束时，$v\left ( t\right )$被设置成已完成的包中最大的结束tag。 第二点不同是当有多个flow竞争时，选择开始tag最小的包进行服务，而不是WFQ中选择结束tag更小的包进行服务。



传统的virtual clock based方法中每个flow的virtual clock累加了其自身所消耗的系统资源(归一化后的)，所以当系统中只有一个flow在跑的时候它的virtual clock会增加不少导致当后面来了多个flow时竞争资源时被unfairly惩罚了。这其实是不合理的，多个flow之间的公平应该是work-conserving的，这种公平性应该是指示了当这些活跃的flow一起竞争时应该怎样进行系统资源的划分，应该是一种无状态的策略，而不应该是定义为从整个使用资源的历史来看最终总体上各个flow的使用份额跟其权值成比例。

SFQ解决这个问题的方法是：

# 四、SFQ(D)
一篇好的paper可以让你迅速地了解该课题相关的工作，在我看完WFQ和SFQ两篇论文之后依然还是没有能够领会这两种方法的意图，但SFQ(D)这篇文章就写的很好，让我一下子就有点看懂了。

# 五、FIOS: 一种公平有效的闪存IO调度器(FAST'12)


# 六、FlashFQ:一种针对SSD的IO公平排队调度器(ATC’13)


